import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import os
from datetime import datetime

# Config
N_CLUSTERS = 3          # N√∫mero de clusters desejados (muito baixo, baixo, alto movimento)
PESSOA_INICIAL = 11     # Come√ßar com a pessoa 11 (primeira do downsampling)

def carregar_dados_pessoa_downsampled(pessoa_id):
    """
    Carrega dados de aceler√¥metro e girosc√≥pio de uma pessoa espec√≠fica (dados com downsampling)
    
    Args:
        pessoa_id: ID da pessoa (n√∫mero)
    
    Returns:
        tuple: (DataFrame aceler√¥metro, DataFrame girosc√≥pio)
    """
    # Caminhos dos arquivos com downsampling
    accel_file = f'Downsampling_data/ds_acelerometro/ds_acelerometro_{pessoa_id}.csv'
    gyro_file = f'Downsampling_data/ds_giroscopio/ds_giroscopio_{pessoa_id}.csv'
    
    # Carregar aceler√¥metro (CSV com cabe√ßalho)
    df_accel = pd.read_csv(accel_file)
    df_accel['timestamp'] = pd.to_datetime(df_accel['timestamp'])
    
    # Carregar girosc√≥pio (CSV com cabe√ßalho)
    df_gyro = pd.read_csv(gyro_file)
    df_gyro['timestamp'] = pd.to_datetime(df_gyro['timestamp'])
    
    return df_accel, df_gyro

def sincronizar_dados(df_accel, df_gyro):
    """
    Sincroniza dados de aceler√¥metro e girosc√≥pio baseado em timestamps
    
    Args:
        df_accel: DataFrame com dados do aceler√¥metro
        df_gyro: DataFrame com dados do girosc√≥pio
    
    Returns:
        DataFrame: Dados sincronizados
    """
    # Renomear colunas do girosc√≥pio para evitar conflito
    df_gyro = df_gyro.rename(columns={'x': 'gx', 'y': 'gy', 'z': 'gz'})
    
    # Merge dos dados usando o timestamp mais pr√≥ximo
    df_accel = df_accel.sort_values('timestamp').reset_index(drop=True)
    df_gyro = df_gyro.sort_values('timestamp').reset_index(drop=True)
    
    # Fazer merge_asof para combinar timestamps pr√≥ximos
    df_combined = pd.merge_asof(
        df_accel, 
        df_gyro, 
        on='timestamp', 
        direction='nearest',
        tolerance=pd.Timedelta(seconds=0.1)
    )
    
    # Remover linhas com valores NaN
    df_combined = df_combined.dropna()
    
    return df_combined

def calcular_features_janela(df, window_size=10):
    """
    Calcula features baseadas em janelas temporais SEM sobreposi√ß√£o.
    Para cada janela, calcula:
    - Magnitude m√©dia do aceler√¥metro (indica intensidade do movimento)
    - Varia√ß√£o (desvio padr√£o) do aceler√¥metro (indica mudan√ßa de movimento - CHAVE!)
    - Magnitude m√©dia do girosc√≥pio (indica rota√ß√£o)
    - Varia√ß√£o (desvio padr√£o) do girosc√≥pio (indica mudan√ßa de rota√ß√£o)
    
    Args:
        df: DataFrame com dados sincronizados (deve ter colunas: x, y, z, gx, gy, gz)
        window_size: Tamanho da janela (n√∫mero de pontos)
    
    Returns:
        tuple: (array de features, array de timestamps correspondentes)
    """
    features = []
    timestamps = []
    
    # Janelas SEM sobreposi√ß√£o (cada ponto pertence a apenas uma janela)
    for i in range(0, len(df) - window_size + 1, window_size):  # Step = window_size (sem overlap)
        window = df.iloc[i:i+window_size]
        
        # Magnitude do aceler√¥metro em cada ponto da janela
        accel_mag = np.sqrt(window['x']**2 + window['y']**2 + window['z']**2)
        
        # Magnitude do girosc√≥pio em cada ponto da janela
        gyro_mag = np.sqrt(window['gx']**2 + window['gy']**2 + window['gz']**2)
        
        # Features estat√≠sticas da janela (priorizar varia√ß√£o sobre magnitude)
        feature_vector = [
            accel_mag.std(),       # 1¬∫: Varia√ß√£o do aceler√¥metro (MAIS IMPORTANTE!)
            accel_mag.mean(),      # 2¬∫: Magnitude m√©dia do aceler√¥metro
            gyro_mag.std(),        # 3¬∫: Varia√ß√£o do girosc√≥pio
            gyro_mag.mean()        # 4¬∫: Magnitude m√©dia do girosc√≥pio
        ]
        
        features.append(feature_vector)
        
        # Timestamp m√©dio da janela
        ts_medio = window['timestamp'].iloc[len(window)//2]
        timestamps.append(ts_medio)
    
    return np.array(features), np.array(timestamps)

def aplicar_kmeans(features, n_clusters=3):
    """
    Aplica K-means clustering nas features
    
    Args:
        features: Array de features (dist√¢ncias euclidianas)
        n_clusters: N√∫mero de clusters
    
    Returns:
        tuple: (modelo KMeans treinado, labels dos clusters, features normalizadas)
    """
    # Normalizar features
    scaler = StandardScaler()
    features_normalized = scaler.fit_transform(features)
    
    # Aplicar K-means
    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    labels = kmeans.fit_predict(features_normalized)
    
    return kmeans, labels, features_normalized

def map_clusters_to_movement(labels, features):
    """
    Mapeia cada cluster para um r√≥tulo de movimento baseado na VARIA√á√ÉO (std) do aceler√¥metro.
    A varia√ß√£o √© o melhor indicador: parado tem varia√ß√£o baixa, movimento tem varia√ß√£o alta.
    
    Retorna um dicion√°rio {cluster_id: movimento_str} e um array de r√≥tulos por ponto.
    """
    unique_clusters = np.unique(labels)
    cluster_mean_std = {}
    
    # Usar a PRIMEIRA feature (std do aceler√¥metro) para ordenar - √© o mais importante!
    for c in unique_clusters:
        cluster_mean_std[c] = features[labels == c, 0].mean()  # Feature 0 = std accel
    
    # Ordenar clusters por varia√ß√£o m√©dia (ascendente: menor varia√ß√£o = mais parado)
    ordered = sorted(cluster_mean_std.items(), key=lambda x: x[1])
    ordered_ids = [c for c, _ in ordered]
    
    # R√≥tulos para 3 clusters ordenados por varia√ß√£o (do menor para o maior)
    movement_names_3 = [
        'muito baixo movimento (parado)',  # Menor varia√ß√£o = parado/dormindo
        'baixo movimento',                  # Varia√ß√£o m√©dia = movimento leve
        'alto movimento'                    # Maior varia√ß√£o = movimento intenso
    ]
    
    if len(ordered_ids) == 3:
        assigned = {cid: movement_names_3[i] for i, cid in enumerate(ordered_ids)}
    else:
        # Gerar r√≥tulos gen√©ricos se n√£o houver exatamente 3 clusters
        assigned = {cid: f'movimento_{i}' for i, cid in enumerate(ordered_ids)}
    
    labels_movement = np.array([assigned[c] for c in labels])
    
    # Debug: mostrar como os clusters foram mapeados
    print("\n   [DEBUG] Mapeamento por varia√ß√£o (std aceler√¥metro):")
    for i, (cid, std_val) in enumerate(ordered):
        print(f"      Cluster {cid} (std m√©dia: {std_val:.4f}) ‚Üí {movement_names_3[i] if len(ordered_ids) == 3 else f'movimento_{i}'}")
    
    return assigned, labels_movement
    
    # R√≥tulos padr√£o para 3 clusters (do menor para o maior)
    movement_names_3 = [
        'muito baixo movimento (parado)',
        'baixo movimento',
        'alto movimento'
    ]
    
    if len(ordered_ids) == 3:
        assigned = {cid: movement_names_3[i] for i, cid in enumerate(ordered_ids)}
    else:
        # Gerar r√≥tulos gen√©ricos se n√£o houver exatamente 3 clusters
        assigned = {cid: f'movimento_{i}' for i, cid in enumerate(ordered_ids)}
    
    labels_movement = np.array([assigned[c] for c in labels])
    return assigned, labels_movement

def plotar_resultados(labels, pessoa_id, timestamps, cluster_name_map, movement_labels):
    """
    Plota os resultados do clustering com timestamps formatados
    
    Args:
        labels: Labels preditos pelo K-means
        pessoa_id: ID da pessoa
        timestamps: Array de timestamps
        cluster_name_map: Dicion√°rio mapeando cluster_id para nome do movimento
        movement_labels: Array de r√≥tulos de movimento por ponto
    """
    fig = plt.figure(figsize=(16, 6))
    
    # Plot 1: Labels ao longo do tempo (usar timestamps formatados no eixo X)
    ax1 = plt.subplot(1, 2, 1)
    
    # Definir cores por r√≥tulo de movimento
    palette = {
        'muito baixo movimento (parado)': 'gray',
        'baixo movimento': 'blue',
        'alto movimento': 'red'
    }
    
    # Fallback para r√≥tulos gen√©ricos
    default_colors = ['tab:blue', 'tab:orange', 'tab:red', 'gray']
    colors = [palette.get(m, default_colors[i % len(default_colors)]) for i, m in enumerate(movement_labels)]
    
    ax1.scatter(timestamps, movement_labels, c=colors, alpha=0.7, s=40)
    ax1.set_xlabel('Hora (HH:MM:SS)', fontsize=12)
    ax1.set_ylabel('R√≥tulo de Movimento', fontsize=12)
    ax1.set_title(f'K-means Clustering - Pessoa {pessoa_id}\n(Baseado em varia√ß√£o - sem sobreposi√ß√£o de janelas)', fontsize=14)
    
    # Formatar eixo X para mostrar hora:minuto:segundo
    ax1.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))
    plt.setp(ax1.xaxis.get_majorticklabels(), rotation=30, ha='right')
    ax1.grid(True, alpha=0.3)
    
    # Plot 2: Distribui√ß√£o por r√≥tulo de movimento
    ax2 = plt.subplot(1, 2, 2)
    unique_mov, counts = np.unique(movement_labels, return_counts=True)
    mov_colors = [palette.get(m, 'tab:blue') for m in unique_mov]
    ax2.bar(unique_mov, counts, color=mov_colors, alpha=0.7)
    ax2.set_xlabel('R√≥tulo de Movimento', fontsize=12)
    ax2.set_ylabel('N√∫mero de Janelas', fontsize=12)
    ax2.set_title('Distribui√ß√£o por R√≥tulo de Movimento', fontsize=14)
    ax2.grid(True, alpha=0.3, axis='y')
    
    # Adicionar valores nas barras
    for i, count in enumerate(counts):
        ax2.text(i, count, str(count), ha='center', va='bottom', fontsize=11, fontweight='bold')
    
    plt.tight_layout()
    output_path = f'upload/ClusterK3euclidianoComDownsampling/clustering_euclidean_pessoa_{pessoa_id}.png'
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.show()
    
    print(f"\n‚úì Gr√°fico salvo como '{output_path}'")

def analisar_pessoa(pessoa_id, n_clusters=3):
    """
    An√°lise completa de clusteriza√ß√£o para uma pessoa usando dist√¢ncia euclidiana
    
    Args:
        pessoa_id: ID da pessoa
        n_clusters: N√∫mero de clusters
    """
    print(f"\n{'='*60}")
    print(f"AN√ÅLISE - PESSOA {pessoa_id}")
    print(f"{'='*60}")
    
    # 1. Carregar dados
    print("\n[1/5] Carregando dados (downsampled)...")
    df_accel, df_gyro = carregar_dados_pessoa_downsampled(pessoa_id)
    print(f"   [OK] Acelerometro: {len(df_accel)} pontos")
    print(f"   [OK] Giroscopio: {len(df_gyro)} pontos")
    
    # 2. Sincronizar dados
    print("\n[2/5] Sincronizando dados de aceler√¥metro e girosc√≥pio...")
    df_combined = sincronizar_dados(df_accel, df_gyro)
    print(f"   ‚úì Dados sincronizados: {len(df_combined)} pontos")
    
    # 3. Calcular features baseadas em janelas temporais
    print(f"\n[3/5] Calculando features em janelas temporais (SEM sobreposi√ß√£o)...")
    features, timestamps = calcular_features_janela(df_combined, window_size=10)
    print(f"   ‚úì {len(features)} janelas processadas (cada janela √© √∫nica)")
    print(f"   ‚úì Features por janela: 4 (std_accel, mag_accel, std_gyro, mag_gyro)")
    print(f"   ‚úì Varia√ß√£o aceler√¥metro m√©dia: {features[:, 0].mean():.4f} (feature principal)")
    
    # 4. Aplicar K-means
    print(f"\n[4/5] Aplicando K-means (k={n_clusters})...")
    kmeans, labels, features_normalized = aplicar_kmeans(features, n_clusters)
    print(f"   ‚úì Clustering conclu√≠do")
    print(f"   ‚úì In√©rcia: {kmeans.inertia_:.2f}")
    
    # 5. Plotar resultados
    print("\n[5/5] Gerando visualiza√ß√£o e rotulando clusters por movimento...")
    cluster_map, movement_labels = map_clusters_to_movement(labels, features)
    plotar_resultados(labels, pessoa_id, timestamps, cluster_map, movement_labels)
    
    # Estat√≠sticas
    print(f"\n{'='*60}")
    print("ESTAT√çSTICAS")
    print(f"{'='*60}")
    
    # Mostrar mapeamento de clusters
    print("\nüìä An√°lise detalhada dos clusters:")
    for cluster_id, movimento in cluster_map.items():
        mask = labels == cluster_id
        count = mask.sum()
        std_accel_media = features[mask, 0].mean()     # Feature 0: varia√ß√£o aceler√¥metro
        mag_accel_media = features[mask, 1].mean()     # Feature 1: magnitude aceler√¥metro
        std_gyro_media = features[mask, 2].mean()      # Feature 2: varia√ß√£o girosc√≥pio
        percentage = (count / len(labels)) * 100
        print(f"\n  üîπ Cluster {cluster_id} ‚Üí {movimento}")
        print(f"     üì¶ {count} janelas ({percentage:.1f}%)")
        print(f"     üìä Varia√ß√£o aceler√¥metro: {std_accel_media:.4f} (crit√©rio principal)")
        print(f"     üìà Magnitude aceler√¥metro: {mag_accel_media:.4f}")
        print(f"     üîÑ Varia√ß√£o girosc√≥pio: {std_gyro_media:.4f}")
    
    return df_combined, features, labels, kmeans, timestamps

def analisar_todas_pessoas(n_clusters=3):
    """
    An√°lise de clusteriza√ß√£o para todas as pessoas (11 a 38)
    
    Args:
        n_clusters: N√∫mero de clusters
    """
    # IDs das pessoas dispon√≠veis (downsampled)
    pessoas = list(range(11, 39))
    
    resultados = {}
    
    print("\n" + "="*60)
    print("AN√ÅLISE DE TODAS AS PESSOAS (DOWNSAMPLED)")
    print("="*60)
    
    for pessoa_id in pessoas:
        try:
            df_combined, features, labels, kmeans, timestamps = analisar_pessoa(
                pessoa_id, n_clusters
            )
            resultados[pessoa_id] = {
                'data': df_combined,
                'features': features,
                'labels': labels,
                'kmeans': kmeans,
                'timestamps': timestamps
            }
        except Exception as e:
            print(f"\n[ERRO] Erro ao processar pessoa {pessoa_id}: {e}")
            continue
    
    # Sum√°rio geral
    print(f"\n\n{'='*60}")
    print("SUM√ÅRIO GERAL")
    print(f"{'='*60}")
    print(f"Total de pessoas analisadas: {len(resultados)}/{len(pessoas)}")
    
    return resultados

if __name__ == "__main__":
    print("\n" + "="*60)
    print("CLUSTERIZA√á√ÉO K-MEANS - VARIA√á√ÉO COMO CRIT√âRIO")
    print("="*60)
    print(f"N√∫mero de clusters: {N_CLUSTERS}")
    print(f"M√©todo: Janelas temporais SEM sobreposi√ß√£o")
    print(f"Features: std_accel (principal), mag_accel, std_gyro, mag_gyro")
    print(f"Crit√©rio: Varia√ß√£o do aceler√¥metro (detecta parado vs movimento)")
    print(f"Dados: Downsampled (50% dos pontos originais)")
    print(f"Tamanho da janela: 10 pontos (SEM overlap)")
    
    # Op√ß√£o: Processar todas as pessoas de uma vez
    print("\n" + "-"*60)
    print("Processando TODAS as pessoas (11-38)")
    print("-"*60)
    
    # Processar todas as pessoas (11 a 38)
    resultados = analisar_todas_pessoas(n_clusters=N_CLUSTERS)
    
    print("\n" + "="*60)
    print("AN√ÅLISE CONCLU√çDA!")
    print("="*60)
    print(f"Total de pessoas processadas: {len(resultados)}")
    print(f"Gr√°ficos salvos em: upload/ClusterK3euclidianoComDownsampling/")
